<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Microphone to Slider</title>
  </head>
  <body>
    <h1>Text</h1>
    <div
      id="hide_this_field"
      style="padding: 1rem; border: 1px solid black; display: none"
    >
      <p>Hier steht wieso wir cool sind.</p>

      <img
        src="https://upload.wikimedia.org/wikipedia/commons/1/1a/Donkey_in_Clovelly%2C_North_Devon%2C_England.jpg"
        alt=""
      />
    </div>
    <label for="slider"
      >Mach LÃ¤rm, um zu sehen, warum Tobi ein cooler Typ ist.</label
    >
    <div style="width: 20vw; display: flex; flex-direction: column">
      <div style="width: 100%; display: flex">
        <div style="width: 30%; text-align: center; background-color: yellow">
          zu leise
        </div>
        <div style="width: 40%; text-align: center; background-color: green">
          perfekt
        </div>
        <div style="width: 30%; text-align: center; background-color: red">
          zu laut
        </div>
      </div>
      <input type="range" id="slider" min="0" max="100" value="0" />
    </div>

    <script>
      document.addEventListener("DOMContentLoaded", () => {
        const slider = document.getElementById("slider");
        const hideField = document.getElementById("hide_this_field");

        // Check if getUserMedia is supported
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          // Request access to the microphone
          navigator.mediaDevices
            .getUserMedia({ audio: true })
            .then((stream) => {
              const audioContext = new (window.AudioContext ||
                window.webkitAudioContext)();
              const source = audioContext.createMediaStreamSource(stream);
              const analyser = audioContext.createAnalyser();

              // Connect the microphone input to the analyser
              source.connect(analyser);
              analyser.connect(audioContext.destination);

              // Set up the analyser
              analyser.fftSize = 512;
              const dataArray = new Uint8Array(analyser.fftSize);

              // Update the slider based on the microphone input
              function updateSlider() {
                analyser.getByteFrequencyData(dataArray);
                const average =
                  dataArray.reduce((acc, value) => acc + value, 0) /
                  dataArray.length;
                const normalizedValue = (average / 256) * 100;

                // The louder the microphone input, the more towards 100 the slider moves (doubled movement twice)
                const mappedValue = normalizedValue * 8; // Adjusted factor for increased movement
                slider.value = mappedValue;

                // Show/hide the content based on the slider value
                if (mappedValue >= 31 && mappedValue <= 61) {
                  hideField.style.display = "block";
                } else {
                  hideField.style.display = "none";
                }
              }

              // Call the updateSlider function periodically
              setInterval(updateSlider, 50);
            })
            .catch((error) => {
              console.error("Error accessing microphone:", error);
            });
        } else {
          console.error("getUserMedia is not supported in this browser");
        }
      });
    </script>
  </body>
</html>
